---
title: "West Nile Virus Biting and Transmission Rates"
author: "Anna Boser"
date: "12/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(data.table)
library(lubridate)
library(stringr)
library(dplyr)
library(sp)
library(raster)
library(ggplot2)
library(suncalc)
library(tidyr)
library(purrr)
library(sf)
library(matlib)
```

#Part 1: The relationship between land surface temperature and air temperature

##Step 1: Retrieve the data
All high qulaity high quality (no clouds or other quality issues) ECOSTRESS measurements at the location of CIMIS monitors in the San Joaquin Valley were matched to the nearest hourly air temperature measurement from the CIMIS station. 
```{r, eval = FALSE}
#get the lost of points for the appears database
# latlon <- data.table(t(read.csv(here::here("ECOSTRESS", "data", "cimis", "LatLonfromsheets.csv"), skip = 4, row.names = 1)))
# latlon$ID <- latlon$ID %>% as.numeric()
# rownames(latlon) <- latlon$ID
# write.csv(latlon, here::here("ECOSTRESS", "data", "cimis", "LatLon.csv"))
#Then use this to get the appears points

#get the ecostress data
get_eco <- function(year){#https://cimis.water.ca.gov/Stations.aspx
  read.csv(here::here("data", "cimis", paste0("sj-points", year), paste0("SJ-points", year, "-ECO2LSTE-001-results.csv")))
}
eco <- rbindlist(lapply(2018:2020, get_eco))

#remove poor quality pixels
eco <- filter(eco, ECO2LSTE_001_SDS_QC_Mandatory_QA_flags_Description == "Pixel produced, best quality")
eco$ECOSTRESS <- eco$ECO2LSTE_001_SDS_LST - 273.15 #in celcius not kelvin
eco <- dplyr::select(eco, Category, ID, Latitude, Longitude, Date, ECOSTRESS)
eco$dt <- ymd_hms(eco$Date, tz = "UTC") %>% with_tz("America/Los_Angeles")
eco$date <- date(eco$dt)
eco$Date <- NULL

#get the cimis data
get_cimis <- function(year){#https://cimis.water.ca.gov/Stations.aspx
  rbind(read.csv(here::here("data", "cimis", paste0("SJ_", year, "_6.csv"))), 
        read.csv(here::here("data", "cimis", paste0("SJ_", year, "_8.csv"))) )
}
cimis <- rbindlist(lapply(2018:2020, get_cimis))

#add date time to cimis
cimis$mid_dt <- ymd_hms(paste(mdy(cimis$Date), 
                              paste0(as.numeric(str_extract(cimis$Hour..PST., regex("[1-9]+"))) - 1, ":30:00")), 
                        tz = "America/Los_Angeles")

cimis <- cimis[!is.na(mid_dt),] # remove NAs

#average duplicate cimis values
cimis <- cimis[, .(Air.Temp..C. = mean(Air.Temp..C.)), by = .(Stn.Id, mid_dt)]

#using the renamed file names, get the list of date times that are closest to the ecostress date times
get_mid_dts <- function(dt){
  dt <- cimis$mid_dt[abs(cimis$mid_dt - dt) == min(abs(cimis$mid_dt - dt))][1]
  dt
}
eco$mid_dt <- lapply(eco$dt, get_mid_dts) %>% purrr::reduce(c) #the closest dts to the times the cimis sensors give us
eco$Stn.Id <- eco$ID
eco$ID <- NULL

#merge ecostress and cimis data by location and date time
Comp_temp <- base::merge(x = eco, 
                         y = dplyr::select(cimis, Stn.Id, mid_dt, Air_Temp = Air.Temp..C.), 
                         by = c("Stn.Id", "mid_dt"), 
                         all.x = TRUE, all.y = FALSE) #sometimes there is more than 1 cimis measurement which is what makes the dataset grow. 

Comp_temp <- Comp_temp[!is.na(Air_Temp),]

Comp_temp$Location <- Comp_temp$Category #This is just what AppEARS called it when I got the data
Comp_temp$Category <- NULL

write.csv(Comp_temp, file = here::here("data", "cimis", "eco_and_cimis.csv"), row.names = FALSE)
```
```{r}
Comp_temp <- read.csv(here::here("data", "cimis", "eco_and_cimis.csv"))
```


Here's what it looks like:
```{r}
ggplot(Comp_temp, aes(x =  ECOSTRESS, y =Air_Temp)) + 
  geom_point(aes(alpha = .2)) +
  stat_function(fun = function(x){x}, aes(color = "One to one"), show.legend = TRUE) + 
  labs(title = "Land surface temperature vs. air temperature in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020", 
       caption = "Air temperature values from CIMIS weather stations.
       Land surface temperature from ECOSTRESS") + 
  ylab("Land Surface Temperature (C)") + 
  xlab("Air Temperature (C)") + 
  ylim(min = 5, max = 45) + 
  xlim(min = 5, max = 60) + 
  guides(alpha = FALSE) +
  theme(legend.title = element_blank())
```


##Step 2: Fit a polynomial to the relationship

To choose my polynomial, I perform graham-schmidt orthogonalization on the sucessive polinomial degress and evaluate the significance of the coefficients. 
```{r, eval = FALSE}
#Graham schmidt
Comp_temp$eco1_orth <- Comp_temp$ECOSTRESS - Proj(Comp_temp$ECOSTRESS, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco2_orth <- Comp_temp$ECOSTRESS^2 - Proj(Comp_temp$ECOSTRESS^2, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^2, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco3_orth <- Comp_temp$ECOSTRESS^3 - Proj(Comp_temp$ECOSTRESS^3, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^3, Comp_temp$eco2_orth) - Proj(Comp_temp$ECOSTRESS^3, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco4_orth <- Comp_temp$ECOSTRESS^4 - Proj(Comp_temp$ECOSTRESS^4, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^4, Comp_temp$eco2_orth) - Proj(Comp_temp$ECOSTRESS^4, Comp_temp$eco3_orth) - Proj(Comp_temp$ECOSTRESS^4, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco5_orth <- Comp_temp$ECOSTRESS^5 - Proj(Comp_temp$ECOSTRESS^5, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^5, Comp_temp$eco2_orth) - Proj(Comp_temp$ECOSTRESS^5, Comp_temp$eco3_orth) - Proj(Comp_temp$ECOSTRESS^5, Comp_temp$eco4_orth) - Proj(Comp_temp$ECOSTRESS^5, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco6_orth <- Comp_temp$ECOSTRESS^6 - Proj(Comp_temp$ECOSTRESS^6, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^6, Comp_temp$eco2_orth) - Proj(Comp_temp$ECOSTRESS^6, Comp_temp$eco3_orth) - Proj(Comp_temp$ECOSTRESS^6, Comp_temp$eco4_orth)  - Proj(Comp_temp$ECOSTRESS^6, Comp_temp$eco5_orth) - Proj(Comp_temp$ECOSTRESS^6, rep(1, length(Comp_temp$ECOSTRESS)))

Comp_temp$eco7_orth <- Comp_temp$ECOSTRESS^7 - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco1_orth) - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco2_orth) - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco3_orth) - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco4_orth)  - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco5_orth) - Proj(Comp_temp$ECOSTRESS^7, Comp_temp$eco6_orth) - Proj(Comp_temp$ECOSTRESS^7, rep(1, length(Comp_temp$ECOSTRESS)))

#polinomial fit
pol_orth <- lm(Air_Temp ~ eco1_orth + eco2_orth + eco3_orth + eco4_orth + eco5_orth + eco6_orth + eco7_orth, data = Comp_temp)
summary(pol_orth)
```
Uhhh this is honestly pretty weird but given the super small additions from 5 and 6 I'm not going to include them. Since the coefficients remain statistically significant until the cubic, we select this model. 

```{r}
Comp_temp$ECOSTRESS2 <- Comp_temp$ECOSTRESS^2
Comp_temp$ECOSTRESS3 <- Comp_temp$ECOSTRESS^3
pol <- lm(Air_Temp ~ ECOSTRESS + ECOSTRESS2 + ECOSTRESS3, data = Comp_temp)
summary(pol)
```

The cubic model's fit: 
Multiple R-squared:  0.8518,	Adjusted R-squared:  0.8516 

What it looks like: 
```{r}
ggplot(Comp_temp, aes(x =  ECOSTRESS, y =Air_Temp)) + 
  geom_point(aes(alpha = .2)) +
  stat_function(fun = function(x){6.906e-01 + 1.432e+00*x -2.213e-02*x^2 + 1.473e-04*x^3}, aes(color = "Cubic polynomial"), show.legend = TRUE) + 
  stat_function(fun = function(x){x}, aes(color = "One to one"), show.legend = TRUE) + 
  labs(title = "Land surface temperature vs. air temperature in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020", 
       caption = "Air temperature values from CIMIS weather stations.
       Land surface temperature from ECOSTRESS") + 
  ylab("Land Surface Temperature (C)") + 
  xlab("Temperature (C)") + 
  ylim(min = 5, max = 45) + 
  xlim(min = 5, max = 60) + 
  guides(alpha = FALSE) +
  theme(legend.title = element_blank())
```


##Step 3: Evaluate how the relationship changes with various other features

###Assessing the effect of time of day and time of year

Day versus night: 
```{r}
#calculate time of day as "dayness." Does the orthogonal component add anything to the model? 
# add sunrise and sunset times to Comp_temp in order to get a day flag
sunrise_sunset <- function(row){
  getSunlightTimes(date = ymd(row[[7]]),
                   lat = row[[3]], 
                   lon = row[[4]],
                   # data = Comp_temp,
                   keep = c("sunrise", "sunset"),
                   tz = "America/Los_Angeles")
}

sunrise_set <- c()
for(i in 1:nrow(Comp_temp)){
  sunrise_set <- rbind(sunrise_set, sunrise_sunset(Comp_temp[i,]))
}

Comp_temp <- merge(Comp_temp, sunrise_set, by.x = c("date", "Latitude", "Longitude"), by.y = c("date", "lat", "lon")) #merge sunrise/sunset data 

Comp_temp$closest_sunset <- Comp_temp$sunset
for (i in 1:length(Comp_temp$closest_sunset)){
  sm1 <- Comp_temp$sunset[i] - lubridate::days(1)
    if (abs(difftime(Comp_temp$dt[i], Comp_temp$sunset[i], units = "hours")) > abs(difftime(Comp_temp$dt[i], sm1, units = "hours"))){
    Comp_temp$closest_sunset[i] <- sm1
    }
}


Comp_temp$daytime <- Comp_temp$dt > Comp_temp$sunrise & Comp_temp$dt < Comp_temp$closest_sunset #if the measurement is between sunrise and sunset
Comp_temp$time_of_day <- ifelse(Comp_temp$daytime, "Day", "Night")
```

Hour into the day: 
```{r}
dayness <- c()
for (i in 1:nrow(Comp_temp)){
  dt = Comp_temp$dt[i]
  sunset = Comp_temp$closest_sunset[i]
  sunrise = Comp_temp$sunrise[i]
  
  if (abs(difftime(dt, sunrise, units = "hours")) < abs(difftime(dt, sunset, units = "hours"))){ #if the time is closer to sunrise than to sunset
    dayn = difftime(dt, sunrise, units = "hours") #how many hours after the sunrise is it (negative values mean night)
  } else {
    dayn = difftime(sunset, dt, units = "hours") #how many hours before sunset is it (negative values mean night)
  }
  dayness <- c(dayness, dayn)
}
Comp_temp$dayness <- dayness
```

Closer to sunset or sunrise: 
```{r}
Comp_temp$morning <- ifelse(abs(Comp_temp$dt - Comp_temp$sunrise) < abs(Comp_temp$dt - Comp_temp$closest_sunset), "sunrise", "sunset")
```

Dawn and dusk: 
```{r}
Comp_temp$dawn <- (Comp_temp$dt > (Comp_temp$sunrise - 2*3600) & Comp_temp$dt < (Comp_temp$sunrise + 2*3600)) #if the measurement is within an hour of dawn
Comp_temp$dusk <- (Comp_temp$dt > (Comp_temp$closest_sunset - 2*3600) & Comp_temp$dt < (Comp_temp$closest_sunset + 2*3600)) #if the measurement is within an hour of dusk
Comp_temp$dawn.dusk <- Comp_temp$dawn|Comp_temp$dusk
```

Deep night:
```{r}
Comp_temp$deepnight <- Comp_temp$dayness < -5
```


Month and year
```{r}
Comp_temp$year <- year(Comp_temp$date)
Comp_temp$month <- month(Comp_temp$date)
```


Landsat data: 
```{r}
#create NDVI and urban classifications using landsat
get_landsat <- function(year){#https://cimis.water.ca.gov/Stations.aspx
  read.csv(here::here("data", "landsat_points", paste0("landsat-july-", year), paste0("Landsat-July-", year, "-CU-LC08-001-results.csv")))
}
landsat <- rbindlist(lapply(2018:2020, get_landsat))
landsat <-landsat[CU_LC08_001_PIXELQA != 1,]
landsat$year <- year(ymd(landsat$Date))
landsat <- landsat[,.(Band1 = mean(CU_LC08_001_SRB1), 
           Band2 = mean(CU_LC08_001_SRB2), 
           Band3 = mean(CU_LC08_001_SRB3), 
           Band4 = mean(CU_LC08_001_SRB4), 
           Band5 = mean(CU_LC08_001_SRB5), 
           Band6 = mean(CU_LC08_001_SRB6), 
           Band7 = mean(CU_LC08_001_SRB7)),by =.(ID, year)]

NDI <- function(b1, b2){
  (b1-b2)/(b1 + b2)
}

landsat$NDVI <- NDI(landsat$Band5, landsat$Band4)
landsat$NDBI <- NDI(landsat$Band6, landsat$Band5)

landsat$vegetated <- landsat$NDVI > 0.4 #chosen at random. Needs to be verified using the fresno image. 
landsat$built <- landsat$NDBI > 0 & landsat$NDVI < 0.12 #chosen at random. Needs to be verified with the fresno image. 
landsat$landcover <- ifelse(landsat$vegetated, "vegetated", "bare")
landsat$landcover <- ifelse(landsat$built, "built", landsat$landcover)

Comp_temp <- base::merge(x = Comp_temp, 
                         y = landsat, 
                         by.x = c("Stn.Id", "year"), 
                         by.y = c("ID", "year"),
                         all.x = TRUE, all.y = FALSE)
```

Ag
```{r}
ag_stns <- st_read(here::here("data", "crop_map", "i15_Crop_Mapping_2016.shp"))
Comp_temp_latlon <- unique(dplyr::select(Comp_temp, Latitude, Longitude, Stn.Id))
Comp_temp_latlon <- st_as_sf(Comp_temp_latlon, coords = c("Longitude", "Latitude"), crs = 4326) %>% st_transform(st_crs(ag_stns))
df <- st_join(Comp_temp_latlon, 
              ag_stns, 
              join = st_within)
stns <- filter(df, !is.na(OBJECTID_1))
stns <- stns$Stn.Id %>% unique()

Comp_temp$Agriculture <- ifelse(Comp_temp$Stn.Id %in% stns, "AG", "notAG")
```


What happens if you just throw everything into a single model
```{r}
full <- lm(Air_Temp ~ ECOSTRESS + ECOSTRESS2 + time_of_day + morning + dayness + NDVI + landcover + year + month + Agriculture +  dawn + dusk + deepnight + Latitude + morning*dayness + morning*time_of_day, data = Comp_temp)
summary(full)
```

NDVI plotted: 
```{r}
ggplot(Comp_temp, aes(x =  ECOSTRESS, y =Air_Temp)) + 
  geom_point(aes(color = NDVI, alpha = .2)) +
  # stat_function(fun = function(x){6.906e-01 + 1.432e+00*x -2.213e-02*x^2 + 1.473e-04*x^3}, show.legend = TRUE) + 
  stat_function(fun = function(x){x}, show.legend = TRUE) + 
  labs(title = "Land surface temperature vs. air temperature in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020", 
       caption = "Air temperature values from CIMIS weather stations.
       Land surface temperature from ECOSTRESS") + 
  ylab("Air Temperature (C)") + 
  xlab("Land Surface Temperature (C)") + 
  ylim(min = 5, max = 45) + 
  xlim(min = 5, max = 60) + 
  scale_colour_gradient(low = "grey", high = "forestgreen") + 
  guides(alpha = FALSE) +
  theme_dark()
```

Dayness plotted: 
```{r}
ggplot(Comp_temp, aes(x =  ECOSTRESS, y =Air_Temp)) + 
  geom_point(aes(color = dayness, alpha = .2)) +
  # stat_function(fun = function(x){6.906e-01 + 1.432e+00*x -2.213e-02*x^2 + 1.473e-04*x^3}, show.legend = TRUE) + 
  stat_function(fun = function(x){x}, show.legend = TRUE) + 
  labs(title = "Land surface temperature vs. air temperature in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020", 
       caption = "Air temperature values from CIMIS weather stations.
       Land surface temperature from ECOSTRESS") + 
  ylab("Air Temperature (C)") + 
  xlab("Land Surface Temperature (C)") + 
  ylim(min = 5, max = 45) + 
  xlim(min = 5, max = 60) + 
  scale_colour_gradient2(low = "blue", high = "red") + 
  guides(alpha = FALSE) +
  theme_dark() + 
  facet_grid(morning~.)

ggplot(Comp_temp, aes(x =  dayness, y =Air_Temp)) + 
  geom_point(aes(color = dayness, alpha = .2)) +
  labs(title = "Land surface temperature vs. air temperature in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020", 
       caption = "Air temperature values from CIMIS weather stations.
       Land surface temperature from ECOSTRESS") + 
  ylab("Air Temperature (C)") + 
  xlab("Land Surface Temperature (C)") + 
  scale_colour_gradient2(low = "blue", high = "red") + 
  guides(alpha = FALSE) +
  theme_dark() + 
  facet_grid(morning~.)
```

```{r}
ggplot(pivot_longer(Comp_temp, cols = c("Air_Temp", "ECOSTRESS"), names_to = "Sensor", values_to = "Temperature"), 
       aes(x = ifelse((hour(dt) + minute(dt)/60 - 0) > 0, (hour(dt) + minute(dt)/60 - 0), (hour(dt) + minute(dt)/60 - 0 + 24)), y = Temperature)) + 
  geom_point(aes(color = Latitude, alpha = .2)) +
  geom_smooth(method = "gam", formula  = y ~ s(x, bs = "cr", k =7)) + 
  xlab("Hour of day") +
  ylab("Temperature (C)") + 
  labs(title = "Temperature by hour of day in the San Joaquin Valley", 
       subtitle = "June - September, 2018 - 2020") + 
  guides(alpha = FALSE) + 
  facet_wrap(~Sensor)
```



#Part 2: Creating and analysing maps of biting and transmission rate

I downloaded all the ECOSTRESS images from appeears June-September 2018-2019 and manually triaged them for quality and no cloud cover. I also renamed them (see WNV original folder) I can then use the relationship described above to correct them to air temperature and apply the equations. For this particular project I am only interested in corrected tarsalis biting and transmission rates at night (under tarsalis_biting and tarsalis_transmission / corrected)
```{r}
files <- list.files(here::here("data", "June-Sept_2018-2020", "renamed"))

files <- files[c(1-3,5-10, 12-16, 19-28, 30-40, 42-52, 54-68, 70-73)]
# y2020 <- files[c(2-3,5-9,12,15,21-22,24,26,34,35,36,37,39,43,46,48,51,52,55,57-58,60-61,63,67,70-72)]
# y2019 <- files[c(1,13-14,19,23,25,27,31-32,38,44,49-50,54,56,59,62,66,73)]
# y2018 <- files[c(10,16:17,20,28,30,33,40,42,45,64:65,68)]

#CHANGE THIS######
correction <- function(x){4.740236 + 1.037816*x - 0.008661*(x^2)} 

apply_equ <- function(file, kind, equation){
  print(file)
  T <- raster(paste0(here::here("data", "June-Sept_2018-2020", "renamed"), "/",
                     file))
  raster <- equation(T)
  raster[is.na(raster[])] <- 0 
  
  dir.create(here::here("data", "June-Sept_2018-2020", kind))
  dir.create(here::here("data", "June-Sept_2018-2020", kind, "not_corrected"))
  writeRaster(raster, paste0(here::here("data", "June-Sept_2018-2020", kind, "not_corrected"), "/",
                             file))
  
  #corrected
  T <- correction(T)
  raster <- equation(T)
  raster[is.na(raster[])] <- 0 
  
  dir.create(here::here("data", "June-Sept_2018-2020", kind, "corrected"))
  writeRaster(raster, paste0(here::here("data", "June-Sept_2018-2020", kind, "corrected"), "/",
                             file))
}

tarsalis_transmission <- function(file){
  apply_equ(file, "tarsalis_transmission", function(T){-(2.94*10^-3) * T * (T - 11.3) * (T - 41.9)})
}

pipiens_infection <- function(file){
  apply_equ(file, "pipiens_infection", function(T){-(2.56*10^-3) * T * (T - 15.6) * (T - 52.2)})
}

tarsalis_biting_rate <- function(file){
  apply_equ(file, "tarsalis_biting_rate", function(T){(1.67*10^-4) * T * (T- 2.3) * (32.0 - T)^(1/2)})
}

pipiens_biting_rate <- function(file){
  apply_equ(file, "pipiens_biting_rate", function(T){(1.70*10^-4) * T * (T- 9.4) * (39.6 - T)^(1/2)})
}

temperature <- function(file){
  apply_equ(file, "temperature", function(T){T})
}

lapply(files, tarsalis_transmission)
lapply(files, pipiens_infection)
lapply(files, tarsalis_biting_rate)
lapply(files, pipiens_biting_rate)
lapply(files, temperature)


```

I use these new files to make time series of biting and transmission rates. 

```{r}
getrow <- function(file, kind, correction = "corrected"){
  print(file)
  
  date <- ymd(substr(file, 14, 23))
  hhmmss <- str_extract(file, regex('[0-9]{2}:{1}[0-9]{2}:{1}[0-9]{2}'))
  dt <- ymd_hms(paste(date, hhmmss), tz = "America/Los_Angeles")

  ras <- raster(paste0(here::here("data", "June-Sept_2018-2020", kind, correction), "/",
                     file))
  
  mean <- cellStats(ras, "mean")
  
  row <- data.frame(date, dt, mean, kind, correction)
}


get_time_series_df <- function(kind, correction = "corrected"){
  files <- list.files(here::here("data", "June-Sept_2018-2020", kind, correction))
  rows <- lapply(files, getrow, kind, correction)
  rbindlist(rows)
}

biting_df <- get_time_series_df("tarsalis_biting_rate", "corrected")
transmission_df <- get_time_series_df("tarsalis_transmission", "corrected")

tarsalis_df <- rbind(biting_df, transmission_df)

temp_df <- rbind(get_time_series_df("temperature", "corrected"),
                 get_time_series_df("temperature", "not_corrected"))
```

Make some nice time series: 
```{r}
ggplot(biting_df, 
       aes(x = ifelse((hour(dt) + minute(dt)/60 - 0) > 0, (hour(dt) + minute(dt)/60 - 0), (hour(dt) + minute(dt)/60 - 0 + 24)), y = mean)) + 
  geom_point(aes(alpha = .2)) +
  geom_smooth(method = "gam", formula  = y ~ s(x, bs = "cr", k =5)) + 
  xlab("Hour of day") +
  ylab("Rate") + 
  labs(title = "Culex tarsalis biting rates", 
       subtitle = "June - September, 2018 - 2020") + 
  guides(alpha = FALSE)

ggplot(transmission_df, 
       aes(x = ifelse((hour(dt) + minute(dt)/60 - 0) > 0, (hour(dt) + minute(dt)/60 - 0), (hour(dt) + minute(dt)/60 - 0 + 24)), y = mean)) + 
  geom_point(aes(alpha = .2)) +
  geom_smooth(method = "gam", formula  = y ~ s(x, bs = "cr", k =5)) + 
  xlab("Hour of day") +
  ylab("Rate") + 
  labs(title = "Culex tarsalis WNV transmission rates", 
       subtitle = "June - September, 2018 - 2020") + 
  guides(alpha = FALSE)
```

```{r}
ggplot(temp_df, 
       aes(x = ifelse((hour(dt) + minute(dt)/60 - 0) > 0, (hour(dt) + minute(dt)/60 - 0), (hour(dt) + minute(dt)/60 - 0 + 24)), y = mean)) + 
  geom_point(aes(alpha = .2)) +
  geom_smooth(method = "gam", formula  = y ~ s(x, bs = "cr", k =7)) + 
  xlab("Hour of day") +
  ylab("Rate") + 
  labs(title = "Culex tarsalis biting rates", 
       subtitle = "June - September, 2018 - 2020") + 
  guides(alpha = FALSE) + 
  facet_wrap(~correction)
```


I use ENVI to look at the new files and decide on the best images to display in a nice map and which ones to only have in the time series. 

Let's make some NVDI and NDBI filters based on landsat images. First I'm going to combine them all into a single image for each year to feed into ENVI, then in ENVI I'm going to create masks based on what looks good. I will then make time series comparing ag/notag, veg/notveg, urban etc.
```{r, eval = FALSE}
# Using the pixelQA, I identified three dates that are good: 2018186, 2019205, 2020208 (one for each year)

movebands <- function(year, day){
  files <- list.files(here::here("data", "Landsat_fresno_july", "raw"))
  files <- files[str_which(files, regex(paste0("doy", year, day)))]
  dir.create(here::here("data", "Landsat_fresno_july", year))
  file.copy(here::here("data", "Landsat_fresno_july", "raw", files), 
            here::here("data", "Landsat_fresno_july", year))
}

movebands(2018, 186)
movebands(2019, 205)
movebands(2020, 208)

# calculate NDVI and NDBI to feed into ENVI

index_create <- function(year, index, b1, b2){
  files <- list.files(here::here("data", "Landsat_fresno_july", year))
  band1 <- files[str_which(files, regex(paste0("SRB", b1)))]
  band2 <- files[str_which(files, regex(paste0("SRB", b2)))]
  
  band1 <- raster(here::here("data", "Landsat_fresno_july", year, band1))
  band2 <- raster(here::here("data", "Landsat_fresno_july", year, band2))
  
  raster <- NDI(band1, band2)
  
  dir.create(here::here("data", "Landsat_fresno_july", index))
  writeRaster(raster, here::here("data", "Landsat_fresno_july", index, paste0(index, year, ".tif")))
}

for (year in 2018:2020){
  index_create(year, "NDVI", 5, 4)
  index_create(year, "NDBI", 6, 5)
}

```


```{r}
ag_poly <- st_read(here::here("data", "crop_map", "i15_Crop_Mapping_2016.shp")) %>%
  st_transform(4326)

ndvi2018 
ndvi2019
ndvi2020

built2018
built2019
built2020

getrow <- function(file, kind, correction = "corrected"){
  print(file)
  
  date <- ymd(substr(file, 14, 23))
  hhmmss <- str_extract(file, regex('[0-9]{2}:{1}[0-9]{2}:{1}[0-9]{2}'))
  dt <- ymd_hms(paste(date, hhmmss), tz = "America/Los_Angeles")

  ras <- raster(paste0(here::here("data", "June-Sept_2018-2020", kind, correction), "/",
                     file))
  
  mean <- cellStats(ras, "mean")
  
  meanfrommask <- function(poly, inv = FALSE){
      y <- mask(raster,
               poly,
               inverse = inv)
      y <- mean(values(y)[!is.na(values(y))])
  }
  
  #AG
  ag <- meanfrommask(ag_poly, FALSE)
  nag <- meanfrommask(ag_poly, TRUE)
  
  #Veg
  veg <- meanfrommask(get(paste0("ndvi", year)), FALSE)
  nveg <- meanfrommask(get(paste0("ndvi", year)), TRUE)
  
  #Built
  built <- meanfrommask(get(paste0("built", year)), FALSE)
  nbuilt <- meanfrommask(get(paste0("built", year)), TRUE)
  
  row <- data.frame(date, dt, mean, ag, nag, veg, nveg, built, nbuilt, kind, correction)
}


get_time_series_df <- function(kind, correction = "corrected"){
  files <- list.files(here::here("data", "June-Sept_2018-2020", kind, correction))
  rows <- lapply(files, getrow, kind, correction)
  rbindlist(rows)
}

biting_df <- get_time_series_df("tarsalis_biting_rate", "corrected")
transmission_df <- get_time_series_df("tarsalis_transmission", "corrected")

tarsalis_df <- rbind(biting_df, transmission_df)

temperature_df <- rbind(get_time_series_df("temperature", "corrected"), 
                        get_time_series_df("temperature", "not_corrected"))
```





